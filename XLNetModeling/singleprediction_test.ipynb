{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"singleprediction_test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b10bf24898664f4eaa5ea46dcc4a5b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d512374ebf37455e8cb7bfa13ffdde50","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_972b64d7f6e746deb9248987b7d19175","IPY_MODEL_4040c5f0f476459fbf0ae44976ad6f37"]}},"d512374ebf37455e8cb7bfa13ffdde50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"972b64d7f6e746deb9248987b7d19175":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f7dd5b7972244008a67071753210af09","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":690,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":690,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d00e91e385142b6a71feded4cc927d5"}},"4040c5f0f476459fbf0ae44976ad6f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7df24fc331dd47a28b16ca9a3e524387","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 690/690 [00:57&lt;00:00, 12.1B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d67fc89caf7b4e8e8e69b2155b99ae2a"}},"f7dd5b7972244008a67071753210af09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7d00e91e385142b6a71feded4cc927d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7df24fc331dd47a28b16ca9a3e524387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d67fc89caf7b4e8e8e69b2155b99ae2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf600f91c12a49fa9994963e1fab427c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dbf590f7cceb4b7ab548bd21690f6703","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2c1336f60c86471fba582860978ffff1","IPY_MODEL_0cb072400569431ea367a9ae3b71a5ad"]}},"dbf590f7cceb4b7ab548bd21690f6703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c1336f60c86471fba582860978ffff1":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_27342d6ee1b44470a8c9f7478115d015","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":467042463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467042463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ffc645eb0eb4fe4a0711785e062df5a"}},"0cb072400569431ea367a9ae3b71a5ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_708132bed7f74b6281b4cfb84c213585","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467M/467M [00:37&lt;00:00, 12.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d8110faf66a474b868864d5a504ed24"}},"27342d6ee1b44470a8c9f7478115d015":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2ffc645eb0eb4fe4a0711785e062df5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"708132bed7f74b6281b4cfb84c213585":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d8110faf66a474b868864d5a504ed24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8aaee9562aab42759e36d40a14fbe689":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_935d0945483f4d9bb4fa3457e5b75d77","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28b907a31ab145ddbc653df012ec8ba8","IPY_MODEL_bbd39341cae340e7b1adba19377d5639"]}},"935d0945483f4d9bb4fa3457e5b75d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28b907a31ab145ddbc653df012ec8ba8":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_66a1c82780bc4d28979754785e91d5b2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":798011,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":798011,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bed9ecb867d44d5e8429adb644011877"}},"bbd39341cae340e7b1adba19377d5639":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_411c8fe6b31a4fe0911682b928605f93","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 798k/798k [00:54&lt;00:00, 14.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24c70bed61fb43edbaca17cf22b73740"}},"66a1c82780bc4d28979754785e91d5b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bed9ecb867d44d5e8429adb644011877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"411c8fe6b31a4fe0911682b928605f93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24c70bed61fb43edbaca17cf22b73740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"LwI0-fi5dwRI","colab_type":"code","outputId":"1eb1e271-f4a1-4095-929a-c4df9598d247","executionInfo":{"status":"ok","timestamp":1585505185665,"user_tz":420,"elapsed":9761,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":666}},"source":["!pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n","\u001b[K     |████████████████████████████████| 542kB 1.4MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 50.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 34.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=43f7dc2493ffa68042cff37a776625da9e9caaa614d2de38352fcffd42945fba\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EpIDvhCTdx37","colab_type":"code","outputId":"ab9624c9-f8f4-4ca7-ec61-a8296e6bf855","executionInfo":{"status":"ok","timestamp":1585505190888,"user_tz":420,"elapsed":3198,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","import os\n","import math\n","\n","import torch\n","from torch.nn import BCEWithLogitsLoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, trange\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"pVWN_b-jdzdo","colab_type":"code","outputId":"5394f744-e9a3-444a-ab4c-71b9597fe8bc","executionInfo":{"status":"ok","timestamp":1585505194415,"user_tz":420,"elapsed":730,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(\"GPU Available: {}\".format(torch.cuda.is_available()))\n","n_gpu = torch.cuda.device_count()\n","print(\"Number of GPU Available: {}\".format(n_gpu))\n","print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))\n","# Edit > Notebook Settings > Put on a GPU "],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU Available: True\n","Number of GPU Available: 1\n","GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a3ouQZcMd1BE","colab_type":"code","outputId":"09944ae7-9809-4811-e5a2-ecf8370d1681","executionInfo":{"status":"ok","timestamp":1585505218681,"user_tz":420,"elapsed":19359,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gi8pPOrDd3vC","colab_type":"code","colab":{}},"source":["class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n","  \n","  def __init__(self, num_labels=2):\n","    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n","    self.num_labels = num_labels\n","    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n","    self.classifier = torch.nn.Linear(768, num_labels)\n","\n","    torch.nn.init.xavier_normal_(self.classifier.weight)\n","\n","  def forward(self, input_ids, token_type_ids=None,\\\n","              attention_mask=None, labels=None):\n","    # last hidden layer\n","    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n","                                   attention_mask=attention_mask,\\\n","                                   token_type_ids=token_type_ids)\n","    # pool the outputs into a mean vector\n","    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n","    logits = self.classifier(mean_last_hidden_state)\n","        \n","    if labels is not None:\n","      loss_fct = BCEWithLogitsLoss()\n","      loss = loss_fct(logits.view(-1, self.num_labels),\\\n","                      labels.view(-1, self.num_labels))\n","      return loss\n","    else:\n","      return logits\n","    \n","  def freeze_xlnet_decoder(self):\n","    \"\"\"\n","    Freeze XLNet weight parameters. They will not be updated during training.\n","    \"\"\"\n","    for param in self.xlnet.parameters():\n","      param.requires_grad = False\n","    \n","  def unfreeze_xlnet_decoder(self):\n","    \"\"\"\n","    Unfreeze XLNet weight parameters. They will be updated during training.\n","    \"\"\"\n","    for param in self.xlnet.parameters():\n","      param.requires_grad = True\n","    \n","  def pool_hidden_state(self, last_hidden_state):\n","    \"\"\"\n","    Pool the output vectors into a single mean vector \n","    \"\"\"\n","    last_hidden_state = last_hidden_state[0]\n","    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n","    return mean_last_hidden_state"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGZ8Vu00d4Y-","colab_type":"code","outputId":"f93caf5c-ae3f-4f0a-a097-3692994bf426","executionInfo":{"status":"ok","timestamp":1585505289502,"user_tz":420,"elapsed":64736,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":132,"referenced_widgets":["b10bf24898664f4eaa5ea46dcc4a5b0a","d512374ebf37455e8cb7bfa13ffdde50","972b64d7f6e746deb9248987b7d19175","4040c5f0f476459fbf0ae44976ad6f37","f7dd5b7972244008a67071753210af09","7d00e91e385142b6a71feded4cc927d5","7df24fc331dd47a28b16ca9a3e524387","d67fc89caf7b4e8e8e69b2155b99ae2a","bf600f91c12a49fa9994963e1fab427c","dbf590f7cceb4b7ab548bd21690f6703","2c1336f60c86471fba582860978ffff1","0cb072400569431ea367a9ae3b71a5ad","27342d6ee1b44470a8c9f7478115d015","2ffc645eb0eb4fe4a0711785e062df5a","708132bed7f74b6281b4cfb84c213585","5d8110faf66a474b868864d5a504ed24"]}},"source":["# Load the saved model \n","\n","checkpoint = torch.load(\"/content/drive/My Drive/Vaccine Capstone/Labelled Dataset/Datasets_XLNet/xlnet_vaccine.bin\")\n","model_state_dict = checkpoint['state_dict']\n","model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n","model.load_state_dict(model_state_dict)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b10bf24898664f4eaa5ea46dcc4a5b0a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=690, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf600f91c12a49fa9994963e1fab427c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=467042463, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"h9inxH6Wd6Sl","colab_type":"code","colab":{}},"source":["# get example text \n","X_train_full = pd.read_csv('/content/drive/My Drive/Vaccine Capstone/Labelled Dataset/Datasets_XLNet/X_train_full_XLNET_March22.csv', \n","                           converters = {'features': eval, 'masks': eval})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Fvo4Vh8d-Is","colab_type":"code","outputId":"d052387e-bc7b-49e2-9011-4001a9ef842e","executionInfo":{"status":"ok","timestamp":1585505636317,"user_tz":420,"elapsed":687,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["example_text = X_train_full.loc[0,'processed'] #string example\n","# this is just an example text, but this is where the string variable should be\n","example_text"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'early age vaccinate black child sure milkis vaccination ingredient 69.05 something brain cell'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"d-xrtYhveAED","colab_type":"code","colab":{}},"source":["# create a test dataframe to feed into generate_predictions_dict function \n","test_df = pd.DataFrame([example_text], columns = ['hash_processed'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZkRXlCOAe3bf","colab_type":"code","outputId":"4e7ec9c3-ff71-49fb-e537-d8b24207780e","executionInfo":{"status":"ok","timestamp":1585505639325,"user_tz":420,"elapsed":354,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["test_df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hash_processed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>early age vaccinate black child sure milkis va...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      hash_processed\n","0  early age vaccinate black child sure milkis va..."]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"bDxrTffOfHR0","colab_type":"code","colab":{}},"source":["def tokenize_inputs(text_list, tokenizer, num_embeddings=512):\n","    \"\"\"\n","    Tokenizes the input text input into ids. Appends the appropriate special\n","    characters to the end of the text to denote end of sentence. Truncate or pad\n","    the appropriate sequence length.\n","    \"\"\"\n","    # tokenize the text, then truncate sequence to the desired length minus 2 for\n","    # the 2 special characters\n","    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n","    # convert tokenized text into numeric ids for the appropriate LM\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    # append special token \"<s>\" and </s> to end of sentence\n","    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n","    # pad sequences\n","    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","    return input_ids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"16w5hKTSf1dU","colab_type":"code","colab":{}},"source":["test_list = test_df['hash_processed'].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aEXaF1lgMgs","colab_type":"code","outputId":"728109b4-de08-46a4-f400-9aa5cb194a5f","executionInfo":{"status":"ok","timestamp":1585505688721,"user_tz":420,"elapsed":3451,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["8aaee9562aab42759e36d40a14fbe689","935d0945483f4d9bb4fa3457e5b75d77","28b907a31ab145ddbc653df012ec8ba8","bbd39341cae340e7b1adba19377d5639","66a1c82780bc4d28979754785e91d5b2","bed9ecb867d44d5e8429adb644011877","411c8fe6b31a4fe0911682b928605f93","24c70bed61fb43edbaca17cf22b73740"]}},"source":["tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8aaee9562aab42759e36d40a14fbe689","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=798011, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NKWtLE2ygDFP","colab_type":"code","colab":{}},"source":["testinput_ids = tokenize_inputs(test_list, tokenizer, num_embeddings=250)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FS3hf5-cgOiO","colab_type":"code","outputId":"9aa6840a-3701-4953-9e30-d50f6f4221ea","executionInfo":{"status":"ok","timestamp":1585505706991,"user_tz":420,"elapsed":729,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["testinput_ids"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  319,   679,  2721, 19142,  8549,   710,   863,   512,  4330,\n","          590, 19507, 16413,  8382,     9,  3739,   359,  2346,  1987,\n","            4,     3,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0]])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"y1o6CkMQgR6O","colab_type":"code","colab":{}},"source":["def create_attn_masks(input_ids):\n","    \"\"\"\n","    Create attention masks to tell model whether attention should be applied to\n","    the input id tokens. Do not want to perform attention on padding tokens.\n","    \"\"\"\n","    # Create attention masks\n","    attention_masks = []\n","\n","    # Create a mask of 1s for each token followed by 0s for padding\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","    return attention_masks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l4rQgIHCgXdl","colab_type":"code","colab":{}},"source":["test_attention_masks = create_attn_masks(testinput_ids)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W63l4sotgavQ","colab_type":"code","colab":{}},"source":["# add input ids and attention masks to the dataframe\n","test_df[\"features\"] = testinput_ids.tolist()\n","test_df[\"masks\"] = test_attention_masks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3hVptFZgmIT","colab_type":"code","outputId":"952733b0-2604-4534-b517-f987c22443fc","executionInfo":{"status":"ok","timestamp":1585505793317,"user_tz":420,"elapsed":613,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["test_df #this is the final DF that will be fed into generate_predictions "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hash_processed</th>\n","      <th>features</th>\n","      <th>masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>early age vaccinate black child sure milkis va...</td>\n","      <td>[319, 679, 2721, 19142, 8549, 710, 863, 512, 4...</td>\n","      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      hash_processed  ...                                              masks\n","0  early age vaccinate black child sure milkis va...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n","\n","[1 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"-BbE7jACgnBe","colab_type":"code","colab":{}},"source":["label_cols = ['Conspiracy: Distrust of government, organizations, big pharma',\n","       'Fear of Critical side-effects (Autism, Brain Damage, SIDS/Death)',\n","       'Fear of Non-critical side-effects (Rash, Pain, Fever, GI problems, Bump on arm)',\n","       'Holistic or alternative medicine', 'Logistic Concerns', 'Pro-vax', 'Religious Beliefs',\n","       'Right to choose',\n","       'Toxic Ingredients, unclear origins of materials/manufacturer',\n","       'Vaccines ineffective/unnecessary']\n","\n","num_labels = len(label_cols)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"780Ep5ScgrmS","colab_type":"code","colab":{}},"source":["# write function that will spit out the labels given the model \n","\n","def generate_predictions_dict(model, df, num_labels, device=\"cpu\", batch_size=32):\n","  num_iter = math.ceil(df.shape[0]/batch_size)\n","  \n","  pred_probs = np.array([]).reshape(0, num_labels)\n","  \n","  model.to(device)\n","  model.eval()\n","  \n","  for i in range(num_iter):\n","    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n","    X = df_subset[\"features\"].values.tolist()\n","    masks = df_subset[\"masks\"].values.tolist()\n","    X = torch.tensor(X)\n","    masks = torch.tensor(masks, dtype=torch.long)\n","    X = X.to(device)\n","    masks = masks.to(device)\n","    with torch.no_grad():\n","      logits = model(input_ids=X, attention_mask=masks)\n","      logits = logits.sigmoid().detach().cpu().numpy()\n","      pred_probs = np.vstack([pred_probs, logits])\n","\n","  result_ind = list(np.round(pred_probs)[0])\n","  # this was the original label column list that was passed to the model when training \n","  #label_cols = ['Conspiracy: Distrust of government, organizations, big pharma',\n","  #     'Fear of Critical side-effects (Autism, Brain Damage, SIDS/Death)',\n","  #     'Fear of Non-critical side-effects (Rash, Pain, Fever, GI problems, Bump on arm)',\n","  #     'Holistic or alternative medicine', 'Logistic Concerns', 'Pro-vax', 'Religious Beliefs',\n","  #     'Right to choose',\n","  #     'Toxic Ingredients, unclear origins of materials/manufacturer',\n","  #     'Vaccines ineffective/unnecessary']\n","  output = {'Fear_of_Critical_Side_Effects__c': result_ind[1] ,\n","            'Fear_of_Delivery_Method__c': result_ind[4], \n","            'Fear_of_Non_Critical_Side_Effects__c': result_ind[2], \n","            'Fear_of_Toxic_Ingredients_c': result_ind[8], \n","            'Holistic_or_Alternative_Medicine__c': result_ind[3], \n","            'Religious_Beliefs_Preclude_Vaccinations__c': result_ind[6], \n","            'Right_to_Choose__c': result_ind[7], \n","            'Vaccines_are_a_Conspiracy': result_ind[0],\n","            'Vaccines_are_Ineffective_or_Unnecessary__c': result_ind[9],\n","            'Patient_is_Pro_Vaccination__c': result_ind[5],\n","            'Hesitancy_Classification__c': 0}\n","  \n","  return output\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KxfYezKEg2ev","colab_type":"code","colab":{}},"source":["prediction = generate_predictions_dict(model, test_df, num_labels, device=\"cuda\", batch_size=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GW1epk5hGnR","colab_type":"code","outputId":"34e1a4f6-cd31-4c93-d65b-d72590472956","executionInfo":{"status":"ok","timestamp":1585506116503,"user_tz":420,"elapsed":485,"user":{"displayName":"Vivian Lu","photoUrl":"","userId":"18182159458826424961"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["prediction"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Fear_of_Critical_Side_Effects__c': 1.0,\n"," 'Fear_of_Delivery_Method__c': 0.0,\n"," 'Fear_of_Non_Critical_Side_Effects__c': 0.0,\n"," 'Fear_of_Toxic_Ingredients_c': 0.0,\n"," 'Hesitancy_Classification__c': 0,\n"," 'Holistic_or_Alternative_Medicine__c': 0.0,\n"," 'Patient_is_Pro_Vaccination__c': 0.0,\n"," 'Religious_Beliefs_Preclude_Vaccinations__c': 0.0,\n"," 'Right_to_Choose__c': 0.0,\n"," 'Vaccines_are_Ineffective_or_Unnecessary__c': 0.0,\n"," 'Vaccines_are_a_Conspiracy': 0.0}"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"ZDioTJP0hfIO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}